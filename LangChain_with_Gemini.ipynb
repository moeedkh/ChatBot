{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moeedkh/ChatBot/blob/main/LangChain_with_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Google Gemini API with LangChain Project**"
      ],
      "metadata": {
        "id": "Sl9hmymDl0kk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Environment Setup and Utility Functions**"
      ],
      "metadata": {
        "id": "kU16yqzE84QT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Install Required Package**\n",
        "\n",
        "**LangChain:** A framework for building applications using large language models, facilitating the creation of language model pipelines.\n",
        "\n",
        "**LangChain Google GenAI Integration:** An integration with Google's Generative AI tools, allowing for the use of advanced language models within the LangChain framework."
      ],
      "metadata": {
        "id": "IOBAlT2al7N9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ts9Ro5dgQevN"
      },
      "outputs": [],
      "source": [
        "# Install the LangChain and LangChain's Google GenAI integration\n",
        "# `-q` keeps the output minimal.\n",
        "# `-U` ensures you are using the latest versions of the packages\n",
        "%pip install -q -U langchain\n",
        "%pip install -q -U langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Resetting the Jupyter Notebook Kernel**"
      ],
      "metadata": {
        "id": "cFFl37bP6PDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OaFyyFGonc3",
        "outputId": "a6104c77-c2ef-44c5-c5b9-02863f3dc55b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Import the IPython library to access its application instance\n",
        "import IPython\n",
        "\n",
        "# Retrieve the current IPython application instance\n",
        "app = IPython.Application.instance()\n",
        "\n",
        "# Perform a complete shutdown of the current IPython kernel including restarting the kernel\n",
        "# it will help the environment to access the new packages\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Defining Helper Functions**\n",
        "\n",
        "When a model returns simple text, it often lacks the formatting needed to make the content easily digestible. By using markdown formatting, we can enhance the presentation of this plain text, transforming it into a structured and visually appealing format. For instance, converting bullet points into asterisks creates clear lists, while indenting text as blockquotes emphasizes important information. This improved formatting not only enhances readability but also helps users engage more effectively with the content, allowing them to grasp key ideas quickly and easily. Overall, proper formatting is essential for conveying information clearly and making the user experience more enjoyable."
      ],
      "metadata": {
        "id": "yPgxlQ3Z8GGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the textwrap module for text formatting and indentation\n",
        "import textwrap\n",
        "\n",
        "# Import the Markdown display function from IPython to render text as Markdown in Jupyter Notebooks\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Define a function 'to_markdown' that converts a given text into Markdown format\n",
        "def to_markdown(text) -> Markdown:\n",
        "    # Replace bullet points (•) with Markdown-compatible bullet points (*)\n",
        "    text: str = text.replace(\"•\", \"  *\")\n",
        "\n",
        "    # Indent the entire text block with the Markdown blockquote symbol ('> ')\n",
        "    # The lambda function ensures every line is indented\n",
        "    return Markdown(textwrap.indent(text, \"> \", predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "S-OFWytF8Lk_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Method 01: Using API key for auth**"
      ],
      "metadata": {
        "id": "g6AMbuuLmiiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Get your API key**\n",
        "\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>"
      ],
      "metadata": {
        "id": "dr_83mNl9rd8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Access your API key in colab**"
      ],
      "metadata": {
        "id": "3MUc_0OP-AT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing userdata from Google Colab to securely store and access API keys\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "YBmxOFrh-MpN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After obtaining the API key, you can access it in Colab\n",
        "\n",
        "* Set the key in the GEMINI_API_KEY environment variable.\n",
        "* You can save this API key under any variable name you prefer.\n",
        "* Remember to enable access for the saved API key in Colab using the toggle button."
      ],
      "metadata": {
        "id": "rotsgU8f-oYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# after saving api key in env variables\n",
        "# get api key from env\n",
        "google_api_key = userdata.get('Gemini_Key')"
      ],
      "metadata": {
        "id": "0NL4LdG4mrj0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Initializing LangChain with GEMINI for AI Chat Responses**"
      ],
      "metadata": {
        "id": "omdHGG_n_Mrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the ChatGoogleGenerativeAI class from the langchain_google_genai module\n",
        "# this will be used for using langchain with gemni\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Import the AIMessage class currently will be used for typing\n",
        "from langchain_core.messages.ai import AIMessage\n",
        "\n",
        "# Initialize an instance of the ChatGoogleGenerativeAI with specific parameters\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # Specify the model to use\n",
        "    api_key=google_api_key,     # Provide the Google API key for authentication\n",
        "    temperature=0.1,            # Set the randomness of the model's responses (0 = deterministic, 1 = very random)\n",
        ")"
      ],
      "metadata": {
        "id": "3-PWGEjH_8Q9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Invoking LangChain Model with Prompt to Get Response**"
      ],
      "metadata": {
        "id": "6nlhwHPDAhF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the AIMessage class currently will be used for typing\n",
        "from langchain_core.messages.human import HumanMessage\n",
        "\n",
        "llm.invoke([HumanMessage(content=\"What is the capital of Bangladesh?\")])"
      ],
      "metadata": {
        "id": "DfCwChy3cDmT",
        "outputId": "c401ecb0-a76d-4828-8569-65d2d4972da6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='There is no country called \"GermanyBangladesh\".  Germany and Bangladesh are two separate countries.\\n\\n* The capital of **Germany** is **Berlin**.\\n* The capital of **Bangladesh** is **Dhaka**.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-d2c0a2fc-48ef-41a6-bfdd-4bb5aedd104b-0', usage_metadata={'input_tokens': 9, 'output_tokens': 44, 'total_tokens': 53, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the LangChain model with a prompt to generate a response\n",
        "ai_msg: AIMessage = llm.invoke(\"What is the capital of Bangladesh?\")\n"
      ],
      "metadata": {
        "id": "JCLYKhCynBtr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display complete response\n",
        "ai_msg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUAhJY2lpn-7",
        "outputId": "4a680472-9f6e-4ad7-db60-1790a627510d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Dhaka\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-492ac693-fe7c-4dc2-bdbe-50961da4dce1-0', usage_metadata={'input_tokens': 8, 'output_tokens': 3, 'total_tokens': 11, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get actual response\n",
        "ai_msg.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "idD2RwpqpqoU",
        "outputId": "cd020a99-0315-4c27-a308-34e9639031aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dhaka\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# format the response with markdown\n",
        "to_markdown(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "w4VJvxUZA7Ce",
        "outputId": "9314eba7-e73d-45ee-bc3b-c998bc6093c7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Dhaka\n"
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Method 02: Using JSON file for Auth**"
      ],
      "metadata": {
        "id": "KIB0oYCvpy0l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o97VoIzdXGy"
      },
      "source": [
        "### **Creating a Json file for Auth or allowing Gemini api in Langchain**\n",
        "Adding Api key to environment variables, and getting it's value sometime cause auth issues, In case of facing Auth Issues, Follow the following steps if you are getting Auth related errors in getting response from Gemini, and being asked for auth.\n",
        "  - Open [Google Cloud Console](https://console.cloud.google.com/), at the top left corner, click on **Select a Project**, a new Window screen will pop up, Select an existing one or create a new Project. (Free Version).\n",
        "  - After Selecting or Creating a project, below **WELCOME** screen, Select **APIs and Services** from **Quick Access**.\n",
        "  - On *APIs and Services* windows, look for Library and left Sidebar. Select **Library**.\n",
        "  - In search box, type **Gemini Api**, two results will be shown,\n",
        "      1. *Gemini Api*\n",
        "      2. *Gemini for google cloud*\n",
        "\n",
        "  Select first one. Click on **Enable**. Gemini Api will be enabled.\n",
        "\n",
        "  - Now get back to **APIs and and Services** Window.\n",
        "  - Select **Credentials**, at Top level, after Credentials, Select **Create Credentail**, and click on API Key from the new dropdown. It will generate an api key.\n",
        "  - Click on **Google Cloud**, at top left corner. It will take you to Welcome page.\n",
        "  - From **Quick Access**, Select **IAM and Admin**.\n",
        "  - At left sidebar select **Service accounts** and click on **Create Service Account**\n",
        "      - Fill in the required Details, click on **Create and Continue**.\n",
        "      - Click on **Select Role**, search of *OWNER*, and select the one with full previlages.\n",
        "      - Click on **Continue**.\n",
        "      - Skip the fields, click on **Done**.\n",
        "      - At *Service Accounts* windows, click on the Email, we just created.\n",
        "      - Click the Newly generated Email.\n",
        "      - At the top, below the Key name where it's mentioned, Click on **KEYS**, from the taskbar above,\n",
        "      - At **Keys** window, select **Add Key**.\n",
        "          - Click on **Create new Key**.\n",
        "          - Select **Add Key**.\n",
        "          - Make sure **JSON** is selected.\n",
        "          - Click on **Create Key**. A New dialogue window will pop up telling you that **Private key saved to your computer**\n",
        "          - The .json file is downloaded to your default download folder.\n",
        "Upload it to the root directory of Colab.\n",
        "          - Right click on the newly add file, select **Copy Path**. Replace it with __your path__ in below cell."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setting Up Google Cloud Application Credentials**\n",
        "\n",
        "Configures the environment by setting the GOOGLE_APPLICATION_CREDENTIALS variable. This variable points to the JSON file containing the necessary credentials for authenticating with Google Cloud services. By doing this, the application can securely access Google Cloud resources using the specified credentials."
      ],
      "metadata": {
        "id": "ExG5DkcCCN1j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZnwV44lr7MS"
      },
      "outputs": [],
      "source": [
        "# Import the os module to interact with the operating system\n",
        "import os\n",
        "\n",
        "# Set the environment variable for Google Cloud application credentials\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"Your path goes here\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Initializing LangChain with GEMINI for AI Chat Responses**"
      ],
      "metadata": {
        "id": "k0Bd540kCtmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the ChatGoogleGenerativeAI class from the langchain_google_genai module\n",
        "# this will be used for using langchain with gemni\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Import the AIMessage class currently will be used for typing\n",
        "from langchain_core.messages.ai import AIMessage\n",
        "\n",
        "# Initialize an instance of the ChatGoogleGenerativeAI with specific parameters\n",
        "# as we are using .json file auth in this case we don't need to specify api key here\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # Specify the model to use\n",
        "    temperature=0.2,            # Set the randomness of the model's responses (0 = deterministic, 1 = very random)\n",
        ")"
      ],
      "metadata": {
        "id": "M0Jr4u-pCw-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Invoking LangChain Model with Prompt to Get Response**"
      ],
      "metadata": {
        "id": "v-NA-QtMDAwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the LangChain model with a prompt to generate a response\n",
        "ai_msg : AIMessage = llm.invoke(\"What is the capital of France?\")"
      ],
      "metadata": {
        "id": "zbr5PHvmC_iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display complete response\n",
        "ai_msg"
      ],
      "metadata": {
        "id": "TceZg7A6DU7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get actual response\n",
        "ai_msg.content"
      ],
      "metadata": {
        "id": "KQIvv5RkDVVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# format the response with markdown\n",
        "to_markdown(ai_msg.content)"
      ],
      "metadata": {
        "id": "_aROZmJfDZri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Invoking LangChain Model with Structured Messages for AI Responses**"
      ],
      "metadata": {
        "id": "R7ihQpV-DnTv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JA4RDvoNkmlk"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "message : list[Dict[str:str]] = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Which open source AI Model is best so far\"},\n",
        "]\n",
        "\n",
        "ai_msg = llm.invoke(message)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ai_msg.content)"
      ],
      "metadata": {
        "id": "Cio28NOyt0KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(ai_msg.content)"
      ],
      "metadata": {
        "id": "d3nc1f0mE943"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "asRE7om_FbVf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}